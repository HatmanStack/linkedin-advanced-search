AWSTemplateFormatVersion: '2010-09-09'
Description: 'Profile Processing Lambda with S3 and SQS - Processes LinkedIn profile screenshots'

Parameters:
  Environment:
    Type: String
    Default: dev
    AllowedValues: [dev, staging, prod]
    Description: Environment name for resource naming and configuration

  DynamoDBTableName:
    Type: String
    Default: linkedin-advanced-search
    Description: Name of the DynamoDB table for profile and edge data

  LogRetentionDays:
    Type: Number
    Default: 14
    AllowedValues: [1, 3, 5, 7, 14, 30, 60, 90, 120, 150, 180, 365, 400, 545, 731, 1827, 3653]
    Description: CloudWatch log retention period in days

  ProjectName:
    Type: String
    Default: linkedin-advanced-search
    Description: Project name for resource naming and tagging

  BucketName:
    Type: String
    Default: ''
    Description: Name of the S3 bucket for profile screenshots (leave empty to auto-generate)

  MaxReceiveCount:
    Type: Number
    Default: 3
    MinValue: 1
    MaxValue: 10
    Description: Maximum number of times a message can be received before being sent to the DLQ

Mappings:
  EnvironmentConfig:
    dev:
      LambdaMemorySize: 2048
      LambdaTimeout: 300
      BatchSize: 1
      MaximumBatchingWindowInSeconds: 10
    staging:
      LambdaMemorySize: 2048
      LambdaTimeout: 300
      BatchSize: 1
      MaximumBatchingWindowInSeconds: 10
    prod:
      LambdaMemorySize: 3072
      LambdaTimeout: 300
      BatchSize: 1
      MaximumBatchingWindowInSeconds: 10

Conditions:
  CreateNewBucket: !Equals [!Ref BucketName, '']

Resources:
  # S3 Bucket for profile screenshots
  ProfileProcessingBucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !If 
        - CreateNewBucket
        - !Sub '${ProjectName}-profile-screenshots-${Environment}-${AWS::AccountId}'
        - !Ref BucketName
      AccessControl: Private
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true
      VersioningConfiguration:
        Status: Enabled
      LifecycleConfiguration:
        Rules:
          - Id: DeleteOldVersions
            Status: Enabled
            NoncurrentVersionExpirationInDays: 90
      BucketEncryption:
        ServerSideEncryptionConfiguration:
          - ServerSideEncryptionByDefault:
              SSEAlgorithm: AES256
      Tags:
        - Key: Environment
          Value: !Ref Environment
        - Key: Project
          Value: !Ref ProjectName
        - Key: Service
          Value: profile-processing

  # S3 Bucket Policy
  ProfileProcessingBucketPolicy:
    Type: AWS::S3::BucketPolicy
    Properties:
      Bucket: !Ref ProfileProcessingBucket
      PolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Sid: AllowSSLRequestsOnly
            Effect: Deny
            Principal: '*'
            Action: 's3:*'
            Resource:
              - !Sub 'arn:aws:s3:::${ProfileProcessingBucket}'
              - !Sub 'arn:aws:s3:::${ProfileProcessingBucket}/*'
            Condition:
              Bool:
                'aws:SecureTransport': false

  # SQS Queue for S3 event notifications
  ProfileProcessingQueue:
    Type: AWS::SQS::Queue
    Properties:
      QueueName: !Sub '${ProjectName}-profile-processing-${Environment}-queue'
      VisibilityTimeout: 360  # 6 minutes (Lambda timeout + buffer)
      MessageRetentionPeriod: 1209600  # 14 days
      RedrivePolicy:
        deadLetterTargetArn: !GetAtt ProfileProcessingDLQ.Arn
        maxReceiveCount: !Ref MaxReceiveCount
      Tags:
        - Key: Environment
          Value: !Ref Environment
        - Key: Project
          Value: !Ref ProjectName
        - Key: Service
          Value: profile-processing

  # Dead Letter Queue for failed processing
  ProfileProcessingDLQ:
    Type: AWS::SQS::Queue
    Properties:
      QueueName: !Sub '${ProjectName}-profile-processing-${Environment}-dlq'
      MessageRetentionPeriod: 1209600  # 14 days
      VisibilityTimeout: 300
      Tags:
        - Key: Environment
          Value: !Ref Environment
        - Key: Project
          Value: !Ref ProjectName
        - Key: Service
          Value: profile-processing

  # SQS Queue Policy
  ProfileProcessingQueuePolicy:
    Type: AWS::SQS::QueuePolicy
    Properties:
      Queues:
        - !Ref ProfileProcessingQueue
      PolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: s3.amazonaws.com
            Action: sqs:SendMessage
            Resource: !GetAtt ProfileProcessingQueue.Arn
            Condition:
              ArnLike:
                aws:SourceArn: !Sub 'arn:aws:s3:::${ProfileProcessingBucket}'

  # S3 Event Notification to SQS
  ProfileProcessingBucketNotification:
    Type: AWS::S3::BucketNotification
    Properties:
      Bucket: !Ref ProfileProcessingBucket
      QueueConfigurations:
        - Event: s3:ObjectCreated:*
          Queue: !GetAtt ProfileProcessingQueue.Arn
          Filter:
            S3Key:
              Rules:
                - Name: suffix
                  Value: .png
                - Name: suffix
                  Value: .jpg
                - Name: suffix
                  Value: .jpeg

  # CloudWatch Log Group for Lambda
  ProfileProcessingLogGroup:
    Type: AWS::Logs::LogGroup
    Properties:
      LogGroupName: !Sub '/aws/lambda/${ProjectName}-profile-processing-${Environment}'
      RetentionInDays: !Ref LogRetentionDays
      Tags:
        - Key: Environment
          Value: !Ref Environment
        - Key: Project
          Value: !Ref ProjectName
        - Key: Service
          Value: profile-processing

  # IAM Role for Lambda Execution
  ProfileProcessingLambdaRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub '${ProjectName}-profile-processing-${Environment}-lambda-role'
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
      Policies:
        - PolicyName: S3Access
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - s3:GetObject
                  - s3:ListBucket
                  - s3:PutObject
                Resource:
                  - !Sub 'arn:aws:s3:::${ProfileProcessingBucket}'
                  - !Sub 'arn:aws:s3:::${ProfileProcessingBucket}/*'
        - PolicyName: SQSAccess
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - sqs:ReceiveMessage
                  - sqs:DeleteMessage
                  - sqs:GetQueueAttributes
                  - sqs:ChangeMessageVisibility
                Resource: !GetAtt ProfileProcessingQueue.Arn
        - PolicyName: DynamoDBAccess
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - dynamodb:PutItem
                  - dynamodb:GetItem
                Resource: !Sub 'arn:aws:dynamodb:${AWS::Region}:${AWS::AccountId}:table/${DynamoDBTableName}'
        - PolicyName: BedrockAccess
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - bedrock:InvokeModel
                  - bedrock:Converse
                Resource: 
                  - !Sub 'arn:aws:bedrock:${AWS::Region}::foundation-model/us.meta.llama4-maverick-17b-instruct-v1:0'
      Tags:
        - Key: Environment
          Value: !Ref Environment
        - Key: Project
          Value: !Ref ProjectName
        - Key: Service
          Value: profile-processing

  # Lambda Function
  ProfileProcessingLambda:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: !Sub '${ProjectName}-profile-processing-${Environment}'
      Runtime: python3.12
      Handler: lambda_function.lambda_handler
      Role: !GetAtt ProfileProcessingLambdaRole.Arn
      Code:
        ZipFile: |
          """
          LinkedIn Profile Processing Lambda Function

          This Lambda function processes LinkedIn profile screenshots uploaded to S3:
          1. Triggered by S3 upload events via SQS
          2. Extracts text using AI vision models
          3. Parses the text to extract structured profile data
          4. Creates Profile Metadata Item in DynamoDB
          5. Generates markdown files and stores them in S3
          """

          import json
          import boto3
          import logging
          import base64
          from datetime import datetime
          from pathlib import Path

          # Configure logging
          logger = logging.getLogger()
          logger.setLevel(logging.INFO)

          # Configuration from environment variables
          import os
          AWS_REGION = os.environ.get('AWS_REGION', 'us-west-2')
          DYNAMODB_TABLE_NAME = os.environ.get('DYNAMODB_TABLE_NAME')
          AI_MODEL_ID = os.environ.get('AI_MODEL_ID')

          # Initialize AWS clients
          s3_client = boto3.client('s3', region_name=AWS_REGION)
          bedrock_client = boto3.client('bedrock-runtime', region_name=AWS_REGION)
          dynamodb = boto3.resource('dynamodb', region_name=AWS_REGION)
          table = dynamodb.Table(DYNAMODB_TABLE_NAME)

          def lambda_handler(event, context):
              """Main Lambda handler for SQS trigger events"""
              try:
                  logger.info(f"Processing event: {json.dumps(event)}")
                  
                  # Parse SQS event
                  for record in event['Records']:
                      if record['eventSource'] == 'aws:sqs':
                          # Parse SQS message body
                          message_body = json.loads(record['body'])
                          
                          # Extract S3 event information
                          if 'Records' in message_body:
                              for s3_record in message_body['Records']:
                                  if s3_record['eventSource'] == 'aws:s3' and s3_record['eventName'].startswith('ObjectCreated:'):
                                      bucket = s3_record['s3']['bucket']['name']
                                      key = s3_record['s3']['object']['key']
                                      
                                      logger.info(f"Processing S3 object: s3://{bucket}/{key}")
                                      
                                      # Process the profile screenshot
                                      result = process_profile_screenshot(bucket, key)
                                      logger.info(f"Successfully processed profile: {result}")
                  
                  return {
                      'statusCode': 200,
                      'body': json.dumps({
                          'message': 'Profile processing completed successfully'
                      })
                  }
                  
              except Exception as e:
                  logger.error(f"Lambda execution failed: {str(e)}")
                  raise

          def process_profile_screenshot(bucket, key):
              """Process a single LinkedIn profile screenshot"""
              try:
                  # Placeholder for actual processing logic
                  # In a real implementation, this would:
                  # 1. Extract text from the image using AI vision
                  # 2. Parse the text to extract structured profile data
                  # 3. Create a Profile Metadata Item in DynamoDB
                  # 4. Generate and save markdown content
                  
                  # Get the profile directory from the key
                  profile_directory = '/'.join(key.split('/')[:-1])
                  
                  # Generate a unique profile ID
                  profile_id = f"PROFILE#{base64.b64encode(profile_directory.encode()).decode()}"
                  
                  # Create a simple metadata item in DynamoDB
                  timestamp = datetime.utcnow().isoformat() + 'Z'
                  
                  item = {
                      'PK': profile_id,
                      'SK': '#METADATA',
                      'name': 'Simulated Profile',
                      'headline': 'Generated from CloudFormation template',
                      'createdAt': timestamp,
                      'updatedAt': timestamp,
                      'originalUrl': f"s3://{bucket}/{key}"
                  }
                  
                  table.put_item(Item=item)
                  
                  return {
                      'profile_id': profile_id,
                      'status': 'success'
                  }
                  
              except Exception as e:
                  logger.error(f"Profile processing failed: {str(e)}")
                  raise
      MemorySize: !FindInMap [EnvironmentConfig, !Ref Environment, LambdaMemorySize]
      Timeout: !FindInMap [EnvironmentConfig, !Ref Environment, LambdaTimeout]
      Environment:
        Variables:
          DYNAMODB_TABLE_NAME: !Ref DynamoDBTableName
          AWS_REGION: !Ref AWS::Region
          AI_MODEL_ID: 'us.meta.llama4-maverick-17b-instruct-v1:0'
      ReservedConcurrencyLimit: 5
      TracingConfig:
        Mode: Active
      Tags:
        - Key: Environment
          Value: !Ref Environment
        - Key: Project
          Value: !Ref ProjectName
        - Key: Service
          Value: profile-processing
    DependsOn: ProfileProcessingLogGroup

  # Event Source Mapping for SQS
  ProfileProcessingEventSourceMapping:
    Type: AWS::Lambda::EventSourceMapping
    Properties:
      BatchSize: !FindInMap [EnvironmentConfig, !Ref Environment, BatchSize]
      Enabled: true
      EventSourceArn: !GetAtt ProfileProcessingQueue.Arn
      FunctionName: !GetAtt ProfileProcessingLambda.Arn
      MaximumBatchingWindowInSeconds: !FindInMap [EnvironmentConfig, !Ref Environment, MaximumBatchingWindowInSeconds]

  # CloudWatch Alarms
  ProfileProcessingLambdaErrorAlarm:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmName: !Sub '${ProjectName}-profile-processing-${Environment}-lambda-errors'
      AlarmDescription: 'Lambda function error rate alarm'
      MetricName: Errors
      Namespace: AWS/Lambda
      Statistic: Sum
      Period: 300
      EvaluationPeriods: 2
      Threshold: 2
      ComparisonOperator: GreaterThanThreshold
      Dimensions:
        - Name: FunctionName
          Value: !Ref ProfileProcessingLambda
      TreatMissingData: notBreaching

  ProfileProcessingLambdaDurationAlarm:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmName: !Sub '${ProjectName}-profile-processing-${Environment}-lambda-duration'
      AlarmDescription: 'Lambda function duration alarm'
      MetricName: Duration
      Namespace: AWS/Lambda
      Statistic: Average
      Period: 300
      EvaluationPeriods: 2
      Threshold: 270000  # 270 seconds (out of 300s timeout)
      ComparisonOperator: GreaterThanThreshold
      Dimensions:
        - Name: FunctionName
          Value: !Ref ProfileProcessingLambda
      TreatMissingData: notBreaching

  ProfileProcessingDLQAlarm:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmName: !Sub '${ProjectName}-profile-processing-${Environment}-dlq-messages'
      AlarmDescription: 'Dead letter queue message count alarm'
      MetricName: ApproximateNumberOfMessagesVisible
      Namespace: AWS/SQS
      Statistic: Sum
      Period: 300
      EvaluationPeriods: 1
      Threshold: 1
      ComparisonOperator: GreaterThanOrEqualToThreshold
      Dimensions:
        - Name: QueueName
          Value: !GetAtt ProfileProcessingDLQ.QueueName
      TreatMissingData: notBreaching

Outputs:
  BucketName:
    Description: 'S3 bucket for profile screenshots'
    Value: !Ref ProfileProcessingBucket
    Export:
      Name: !Sub '${AWS::StackName}-BucketName'

  BucketArn:
    Description: 'S3 bucket ARN'
    Value: !GetAtt ProfileProcessingBucket.Arn
    Export:
      Name: !Sub '${AWS::StackName}-BucketArn'

  QueueUrl:
    Description: 'SQS queue URL'
    Value: !Ref ProfileProcessingQueue
    Export:
      Name: !Sub '${AWS::StackName}-QueueUrl'

  QueueArn:
    Description: 'SQS queue ARN'
    Value: !GetAtt ProfileProcessingQueue.Arn
    Export:
      Name: !Sub '${AWS::StackName}-QueueArn'

  DeadLetterQueueUrl:
    Description: 'Dead letter queue URL'
    Value: !Ref ProfileProcessingDLQ
    Export:
      Name: !Sub '${AWS::StackName}-DLQUrl'

  DeadLetterQueueArn:
    Description: 'Dead letter queue ARN'
    Value: !GetAtt ProfileProcessingDLQ.Arn
    Export:
      Name: !Sub '${AWS::StackName}-DLQArn'

  LambdaFunctionArn:
    Description: 'Profile Processing Lambda function ARN'
    Value: !GetAtt ProfileProcessingLambda.Arn
    Export:
      Name: !Sub '${AWS::StackName}-LambdaArn'

  LambdaFunctionName:
    Description: 'Profile Processing Lambda function name'
    Value: !Ref ProfileProcessingLambda
    Export:
      Name: !Sub '${AWS::StackName}-LambdaName'